# âœ… ê¸°ì¡´ ì½”ë“œ
import feedparser
from datetime import datetime
from sqlalchemy.orm import Session
from database import SessionLocal
from models.news import News

# âœ… [1] ìƒˆë¡œ ì¶”ê°€
import requests
from bs4 import BeautifulSoup

RSS_URL = "https://news.google.com/rss/search?q=ë³´ë””ë¹Œë”©&hl=ko&gl=KR&ceid=KR:ko"

# âœ… [2] ì¸ë„¤ì¼ ì´ë¯¸ì§€ ì¶”ì¶œ í•¨ìˆ˜ ì¶”ê°€
def extract_thumbnail(link: str) -> str:
    try:
        headers = {"User-Agent": "Mozilla/5.0"}
        response = requests.get(link, headers=headers, timeout=5)
        soup = BeautifulSoup(response.content, "html.parser")

        # og:image ë©”íƒ€íƒœê·¸ ìš°ì„ 
        og_image = soup.find("meta", property="og:image")
        if og_image and og_image.get("content"):
            return og_image["content"]

        # ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ <img> íƒœê·¸ ì‚¬ìš©
        img_tag = soup.find("img")
        if img_tag and img_tag.get("src"):
            return img_tag["src"]

    except Exception as e:
        print(f"[ì¸ë„¤ì¼ ì¶”ì¶œ ì‹¤íŒ¨] {link} â†’ {e}")
    return ""  # ì‹¤íŒ¨ ì‹œ ë¹ˆ ë¬¸ìì—´

# âœ… ê¸°ì¡´ fetch_news í•¨ìˆ˜ ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ë©´ì„œ ë‚´ë¶€ë§Œ ìˆ˜ì •
def fetch_news():
    print("ğŸ“° [ë‰´ìŠ¤ ìˆ˜ì§‘] ì‹œì‘")
    feed = feedparser.parse(RSS_URL)

    db: Session = SessionLocal()

    for entry in feed.entries:
        title = entry.title
        link = entry.link
        published = datetime(*entry.published_parsed[:6])

        # ì¤‘ë³µ ë°©ì§€
        existing = db.query(News).filter_by(title=title, link=link).first()
        if existing:
            continue

        # âœ… [3] ì¸ë„¤ì¼ ì¶”ì¶œ
        image_url = extract_thumbnail(link)

        new_article = News(
            title=title,
            link=link,
            image_url=image_url,  # â† ì—¬ê¸° ë³€ê²½ë¨
            created_at=published
        )
        db.add(new_article)

    db.commit()
    db.close()
    print("âœ… [ë‰´ìŠ¤ ìˆ˜ì§‘] ì™„ë£Œ")
